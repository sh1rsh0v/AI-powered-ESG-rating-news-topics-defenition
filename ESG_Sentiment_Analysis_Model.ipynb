{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "id": "gZFujblcO0UT",
        "outputId": "956b2684-f1aa-479c-b138-f0f1833fe3cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['train.json', 'test.json', 'sample.csv']\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import os\n",
        "print(os.listdir(\"../input\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "id": "0JlbA4EDO0UV",
        "outputId": "7c3662d0-2de1-400b-f963-efb2d7d74ff1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train sentences: 8263\n",
            "Train labels: 8263\n",
            "Test sentences: 2056\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "test_file = '../input/test.json'\n",
        "train_file = '../input/train.json'\n",
        "\n",
        "x_train, y_train, x_test, test_inds = [], [], [], []\n",
        "\n",
        "with open(test_file) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "    for row in data:\n",
        "        x_test.append(row['text'])\n",
        "        test_inds.append(row['id'])\n",
        "\n",
        "with open(train_file) as json_file:\n",
        "    data = json.load(json_file)\n",
        "\n",
        "    for row in data:\n",
        "        sentiment = -1\n",
        "\n",
        "        if row['sentiment'] == 'negative':\n",
        "            sentiment = 0\n",
        "        elif row['sentiment'] == 'neutral':\n",
        "            sentiment = 1\n",
        "        else:\n",
        "            sentiment = 2\n",
        "\n",
        "        if sentiment == -1:\n",
        "            continue\n",
        "\n",
        "        x_train.append(row['text'])\n",
        "        y_train.append(sentiment)\n",
        "\n",
        "print('Train sentences: {}'.format(len(x_train)))\n",
        "print('Train labels: {}'.format(len(y_train)))\n",
        "print('Test sentences: {}'.format(len(x_test)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y-avKOxWO0UW",
        "outputId": "c8ce1fa8-50c5-48ec-9fae-db5c1f5e0fd6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "np_x_train shape: (8263, 5000)\n",
            "np_x_test shape: (2056, 5000)\n",
            "np_y_train shape: (8263, 3)\n"
          ]
        }
      ],
      "source": [
        "from keras.preprocessing import text, sequence\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "max_length = 5000\n",
        "max_features = 20000\n",
        "embedding_dim = 300\n",
        "\n",
        "x_all = []\n",
        "x_all.extend(x_test)\n",
        "x_all.extend(x_train)\n",
        "\n",
        "tk = Tokenizer(num_words=max_features, lower=True, filters='\\n\\t')\n",
        "tk.fit_on_texts(x_all)\n",
        "x_train_seq = tk.texts_to_sequences(x_train)\n",
        "x_test_seq = tk.texts_to_sequences(x_test)\n",
        "\n",
        "np_x_train = pad_sequences(x_train_seq, maxlen=max_length,  padding='post')\n",
        "np_x_test = pad_sequences(x_test_seq, maxlen=max_length,  padding='post')\n",
        "np_y_train = to_categorical(y_train)\n",
        "\n",
        "class_num = np_y_train.shape[1]\n",
        "\n",
        "print ('np_x_train shape: {}'.format(np_x_train.shape))\n",
        "print ('np_x_test shape: {}'.format(np_x_test.shape))\n",
        "print ('np_y_train shape: {}'.format(np_y_train.shape))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gw0Bbk-BO0UW",
        "outputId": "9202cdbe-165e-47bf-9492-3d36df76dc81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 5000)              0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 5000, 300)         6000000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4992, 32)          86432     \n",
            "_________________________________________________________________\n",
            "maxpool1d_1 (MaxPooling1D)   (None, 312, 32)           0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 312, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 306, 32)           7200      \n",
            "_________________________________________________________________\n",
            "maxpool1d_2 (MaxPooling1D)   (None, 38, 32)            0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 38, 32)            0         \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 64)                16640     \n",
            "_________________________________________________________________\n",
            "preds (Dense)                (None, 3)                 195       \n",
            "=================================================================\n",
            "Total params: 6,110,467\n",
            "Trainable params: 6,110,467\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "WARNING:tensorflow:From /opt/conda/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 34s 6ms/step - loss: 1.0078 - acc: 0.4900 - val_loss: 0.9230 - val_acc: 0.4792\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.7423 - acc: 0.6532 - val_loss: 0.6860 - val_acc: 0.7015\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.4310 - acc: 0.8368 - val_loss: 0.8310 - val_acc: 0.6841\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 33s 6ms/step - loss: 1.0180 - acc: 0.4872 - val_loss: 1.0027 - val_acc: 0.4792\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.7679 - acc: 0.6573 - val_loss: 0.6837 - val_acc: 0.6890\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.4177 - acc: 0.8463 - val_loss: 0.7547 - val_acc: 0.6914\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 34s 6ms/step - loss: 0.9928 - acc: 0.5066 - val_loss: 0.8192 - val_acc: 0.5938\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.7421 - acc: 0.6558 - val_loss: 0.7188 - val_acc: 0.6777\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.4748 - acc: 0.8179 - val_loss: 0.7961 - val_acc: 0.6805\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 35s 6ms/step - loss: 1.0146 - acc: 0.4905 - val_loss: 0.9535 - val_acc: 0.5131\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.7451 - acc: 0.6751 - val_loss: 0.6760 - val_acc: 0.6983\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.4223 - acc: 0.8361 - val_loss: 0.7684 - val_acc: 0.6874\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 35s 6ms/step - loss: 1.0102 - acc: 0.4881 - val_loss: 0.9205 - val_acc: 0.4792\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.7309 - acc: 0.6582 - val_loss: 0.6889 - val_acc: 0.7007\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.4279 - acc: 0.8344 - val_loss: 0.7616 - val_acc: 0.6971\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 34s 6ms/step - loss: 1.0097 - acc: 0.4903 - val_loss: 0.9334 - val_acc: 0.4772\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.7139 - acc: 0.6788 - val_loss: 0.6839 - val_acc: 0.7035\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.4038 - acc: 0.8499 - val_loss: 0.8036 - val_acc: 0.6858\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 36s 6ms/step - loss: 0.9848 - acc: 0.5031 - val_loss: 0.8199 - val_acc: 0.6035\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.7171 - acc: 0.6802 - val_loss: 0.7342 - val_acc: 0.6636\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.4683 - acc: 0.8186 - val_loss: 0.8405 - val_acc: 0.6704\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 38s 7ms/step - loss: 0.9886 - acc: 0.5173 - val_loss: 0.8472 - val_acc: 0.6127\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.7325 - acc: 0.6656 - val_loss: 0.7107 - val_acc: 0.6761\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.4656 - acc: 0.8228 - val_loss: 0.7777 - val_acc: 0.6902\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 36s 6ms/step - loss: 0.9800 - acc: 0.4929 - val_loss: 0.8584 - val_acc: 0.5563\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.7225 - acc: 0.6655 - val_loss: 0.7247 - val_acc: 0.6809\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.4648 - acc: 0.8190 - val_loss: 0.8091 - val_acc: 0.6809\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n",
            "Train on 5784 samples, validate on 2479 samples\n",
            "Epoch 1/10\n",
            "5784/5784 [==============================] - 37s 6ms/step - loss: 1.0093 - acc: 0.4924 - val_loss: 0.9501 - val_acc: 0.5672\n",
            "Epoch 2/10\n",
            "5784/5784 [==============================] - 31s 5ms/step - loss: 0.7824 - acc: 0.6596 - val_loss: 0.7160 - val_acc: 0.6890\n",
            "Epoch 3/10\n",
            "5784/5784 [==============================] - 30s 5ms/step - loss: 0.4493 - acc: 0.8332 - val_loss: 0.7568 - val_acc: 0.6926\n",
            "Restoring model weights from the end of the best epoch\n",
            "Epoch 00003: early stopping\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import *\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "def one_input_classifier(max_length, max_features, embedding_dim, class_num):\n",
        "    inputs = Input(shape=(max_length,), name='input_1')\n",
        "    embeddings = Embedding(max_features, embedding_dim, input_length=max_length, name='embedding_1')(inputs)\n",
        "\n",
        "    conv_1 = Conv1D(32, 9, activation='relu', name='conv1d_1')(embeddings)\n",
        "    maxpool_1 = MaxPooling1D(16, name='maxpool1d_1')(conv_1)\n",
        "    dropout_1 = Dropout(0.2, name='dropout_1')(maxpool_1)\n",
        "\n",
        "    conv_2 = Conv1D(32, 7, activation='relu', name='conv1d_2')(dropout_1)\n",
        "    maxpool_2 = MaxPooling1D(8, name='maxpool1d_2')(conv_2)\n",
        "    dropout_2 = Dropout(0.2, name='dropout_2')(maxpool_2)\n",
        "\n",
        "    bilstm = Bidirectional(LSTM(32, dropout=0.2, recurrent_dropout=0.2, name='lstm_1'),\n",
        "        name='bidirectional_1')(dropout_2)\n",
        "    preds = Dense(class_num, activation='softmax', name='preds')(bilstm)\n",
        "\n",
        "    model = Model(inputs=inputs, outputs=preds)\n",
        "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=1,\n",
        "                               mode='min', baseline=None, restore_best_weights=True)\n",
        "\n",
        "models = []\n",
        "classifier_num = 10\n",
        "\n",
        "for i in range(classifier_num):\n",
        "    model = one_input_classifier(max_length, max_features, embedding_dim, class_num)\n",
        "\n",
        "    if i == 0:\n",
        "        print(model.summary())\n",
        "\n",
        "    model.fit(np_x_train, np_y_train, validation_split=0.3, shuffle=True,\n",
        "              callbacks=[early_stopping], epochs=10, batch_size=32, verbose=1)\n",
        "    models.append(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64kScqiNO0UX",
        "outputId": "035631c2-96f8-4be6-c462-d0d85bfc7c99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2056/2056 [==============================] - 5s 3ms/step\n",
            "2056/2056 [==============================] - 6s 3ms/step\n",
            "2056/2056 [==============================] - 5s 3ms/step\n",
            "2056/2056 [==============================] - 5s 2ms/step\n",
            "2056/2056 [==============================] - 6s 3ms/step\n",
            "2056/2056 [==============================] - 5s 3ms/step\n",
            "2056/2056 [==============================] - 5s 2ms/step\n",
            "2056/2056 [==============================] - 5s 2ms/step\n",
            "2056/2056 [==============================] - 5s 2ms/step\n",
            "2056/2056 [==============================] - 5s 2ms/step\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "y_pred_list = []\n",
        "\n",
        "for i in range(classifier_num):\n",
        "    y_pred = models[i].predict(np_x_test, batch_size=32, verbose=1)\n",
        "    y_pred_list.append(y_pred)\n",
        "\n",
        "print(len(y_pred_list))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xuvw5USRO0UX",
        "outputId": "a0ae805b-5cd1-4139-c4a2-d8364d10b5c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   id sentiment\n",
            "0   0  positive\n",
            "1   1  positive\n",
            "2   2  negative\n",
            "3   3  positive\n",
            "4   4  negative\n"
          ]
        }
      ],
      "source": [
        "test_num = np_x_test.shape[0]\n",
        "y_pred = np.ndarray(shape=(test_num,), dtype=np.int32)\n",
        "\n",
        "for i in range(test_num):\n",
        "    votes = []\n",
        "\n",
        "    for j in range(classifier_num):\n",
        "        vote = y_pred_list[j][i].argmax(axis=0).astype(int)\n",
        "        votes.append(vote)\n",
        "\n",
        "    vote_final = max(set(votes), key=votes.count)\n",
        "    y_pred[i] = vote_final\n",
        "\n",
        "predicted_classes = []\n",
        "filename = 'submission.csv'\n",
        "\n",
        "for i, y_val in enumerate(y_pred):\n",
        "    if y_val == 0:\n",
        "        predicted_classes.append((test_inds[i], 'negative'))\n",
        "    elif y_val == 1:\n",
        "        predicted_classes.append((test_inds[i], 'neutral'))\n",
        "    else:\n",
        "        predicted_classes.append((test_inds[i], 'positive'))\n",
        "\n",
        "sub = pd.DataFrame(data=predicted_classes, columns=['id', 'sentiment'])\n",
        "sub.to_csv(filename, index=False)\n",
        "print(sub.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "O0UKHVEJ_sz3",
        "outputId": "fbb7c217-fe03-4b40-be8d-84e519dd923f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 58,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "sub[\"sentiment\"].hist()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}